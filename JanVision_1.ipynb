{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3c259ffe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ GPU not detected. Training on Ryzen CPU. (Check CUDA installation)\n",
      "Ultralytics 8.4.14  Python-3.13.5 torch-2.10.0+cpu CPU (AMD Ryzen 7 7435HS)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, angle=1.0, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=data.yaml, degrees=0.0, deterministic=True, device=cpu, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, end2end=None, epochs=15, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolo11n.pt, momentum=0.937, mosaic=1.0, multi_scale=0.0, name=train7, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, rle=1.0, save=True, save_conf=False, save_crop=False, save_dir=C:\\Users\\praha\\Downloads\\JanVision_2.ipynb\\runs\\detect\\train7, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=3\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
      "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
      "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    111296  ultralytics.nn.modules.block.C3k2            [384, 128, 1, False]          \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1     32096  ultralytics.nn.modules.block.C3k2            [256, 64, 1, False]           \n",
      " 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1     86720  ultralytics.nn.modules.block.C3k2            [192, 128, 1, False]          \n",
      " 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n",
      " 23        [16, 19, 22]  1    431257  ultralytics.nn.modules.head.Detect           [3, 16, None, [64, 128, 256]] \n",
      "YOLO11n summary: 182 layers, 2,590,425 parameters, 2,590,409 gradients, 6.4 GFLOPs\n",
      "\n",
      "Transferred 448/499 items from pretrained weights\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 669.5143.8 MB/s, size: 122.9 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\praha\\Downloads\\JanVision_2.ipynb\\janvision_dataset\\janvision_dataset\\labels\\train... 338 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 338/338 1.5Kit/s 0.2s<0.1s\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: C:\\Users\\praha\\Downloads\\JanVision_2.ipynb\\janvision_dataset\\janvision_dataset\\labels\\train.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mImageCompression.__init__() got an unexpected keyword argument 'quality_range'\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 588.599.8 MB/s, size: 124.1 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\praha\\Downloads\\JanVision_2.ipynb\\janvision_dataset\\janvision_dataset\\labels\\val... 85 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 85/85 1.4Kit/s 0.1s\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: C:\\Users\\praha\\Downloads\\JanVision_2.ipynb\\janvision_dataset\\janvision_dataset\\labels\\val.cache\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001429, momentum=0.9) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.0005), 87 bias(decay=0.0)\n",
      "Plotting labels to C:\\Users\\praha\\Downloads\\JanVision_2.ipynb\\runs\\detect\\train7\\labels.jpg... \n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mC:\\Users\\praha\\Downloads\\JanVision_2.ipynb\\runs\\detect\\train7\u001b[0m\n",
      "Starting training for 15 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       1/15         0G      0.855      2.941      1.472          2        640: 100% ━━━━━━━━━━━━ 22/22 4.6s/it 1:412.1sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 5.8s/it 17.4s<12.8s\n",
      "                   all         85         85     0.0149          1      0.591      0.339\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       2/15         0G       0.69      2.131      1.258          5        640: 100% ━━━━━━━━━━━━ 22/22 4.8s/it 1:461.6ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 4.2s/it 12.6s.3s1s\n",
      "                   all         85         85     0.0135          1      0.919      0.631\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       3/15         0G     0.7045      1.543      1.228          5        640: 100% ━━━━━━━━━━━━ 22/22 4.5s/it 1:391.7sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 3.6s/it 10.8s.0s1s\n",
      "                   all         85         85          1      0.381      0.965      0.816\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       4/15         0G     0.6077      1.306       1.16          6        640: 100% ━━━━━━━━━━━━ 22/22 5.0s/it 1:502.2ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 3.4s/it 10.2s.5s8s\n",
      "                   all         85         85      0.538       0.47      0.556      0.475\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       5/15         0G     0.6174      1.155      1.157          6        640: 100% ━━━━━━━━━━━━ 22/22 4.8s/it 1:452.0sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 3.3s/it 9.8s7.2s5s\n",
      "                   all         85         85      0.679      0.452      0.371      0.186\n",
      "Closing dataloader mosaic\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mImageCompression.__init__() got an unexpected keyword argument 'quality_range'\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       6/15         0G     0.5344      1.803      1.248          2        640: 100% ━━━━━━━━━━━━ 22/22 4.3s/it 1:341.7sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 2.9s/it 8.7s6.5s4s\n",
      "                   all         85         85      0.559      0.414      0.431      0.358\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       7/15         0G     0.4846      1.575      1.217          2        640: 100% ━━━━━━━━━━━━ 22/22 4.2s/it 1:321.5sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 2.8s/it 8.5s6.3s4s\n",
      "                   all         85         85       0.99          1      0.995      0.812\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       8/15         0G     0.4173      1.253      1.122          2        640: 100% ━━━━━━━━━━━━ 22/22 4.3s/it 1:352.2sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 3.4s/it 10.2s.5s9s\n",
      "                   all         85         85      0.949      0.969      0.991      0.865\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       9/15         0G     0.3614      1.128      1.081          2        640: 100% ━━━━━━━━━━━━ 22/22 4.8s/it 1:451.8sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 3.4s/it 10.2s.7s1s\n",
      "                   all         85         85      0.852      0.806      0.776      0.731\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      10/15         0G     0.3251      1.082     0.9948          2        640: 100% ━━━━━━━━━━━━ 22/22 4.4s/it 1:371.7sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 2.8s/it 8.5s6.2s2s\n",
      "                   all         85         85      0.962      0.954      0.994      0.952\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      11/15         0G     0.2991     0.9627      1.005          2        640: 100% ━━━━━━━━━━━━ 22/22 4.2s/it 1:321.5sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 2.9s/it 8.6s6.4s7s\n",
      "                   all         85         85      0.892      0.949      0.934      0.823\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      12/15         0G     0.2867     0.9224     0.9988          2        640: 100% ━━━━━━━━━━━━ 22/22 4.2s/it 1:321.7sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 2.9s/it 8.8s6.6s4s\n",
      "                   all         85         85      0.947      0.998      0.994       0.93\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      13/15         0G     0.2587     0.8223     0.9423          2        640: 100% ━━━━━━━━━━━━ 22/22 4.2s/it 1:321.5sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 2.8s/it 8.5s6.3s6s\n",
      "                   all         85         85      0.981          1      0.995      0.974\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      14/15         0G     0.2447     0.8362     0.9567          2        640: 100% ━━━━━━━━━━━━ 22/22 4.2s/it 1:321.7sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 2.8s/it 8.5s6.3s4s\n",
      "                   all         85         85      0.944      0.965      0.993      0.978\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      15/15         0G     0.2048     0.7597     0.9228          2        640: 100% ━━━━━━━━━━━━ 22/22 4.2s/it 1:321.5sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 2.9s/it 8.6s6.4s9s\n",
      "                   all         85         85      0.947       0.97      0.993      0.957\n",
      "\n",
      "15 epochs completed in 0.451 hours.\n",
      "Optimizer stripped from C:\\Users\\praha\\Downloads\\JanVision_2.ipynb\\runs\\detect\\train7\\weights\\last.pt, 5.5MB\n",
      "Optimizer stripped from C:\\Users\\praha\\Downloads\\JanVision_2.ipynb\\runs\\detect\\train7\\weights\\best.pt, 5.5MB\n",
      "\n",
      "Validating C:\\Users\\praha\\Downloads\\JanVision_2.ipynb\\runs\\detect\\train7\\weights\\best.pt...\n",
      "Ultralytics 8.4.14  Python-3.13.5 torch-2.10.0+cpu CPU (AMD Ryzen 7 7435HS)\n",
      "YOLO11n summary (fused): 101 layers, 2,582,737 parameters, 0 gradients, 6.3 GFLOPs\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 2.5s/it 7.5s5.6ss\n",
      "                   all         85         85      0.944      0.965      0.993      0.978\n",
      "           Keratoconus         28         28          1      0.895      0.995      0.949\n",
      "                Normal         36         36       0.98          1      0.995      0.995\n",
      "               Suspect         21         21      0.851          1      0.989      0.989\n",
      "Speed: 1.6ms preprocess, 74.5ms inference, 0.0ms loss, 3.0ms postprocess per image\n",
      "Results saved to \u001b[1mC:\\Users\\praha\\Downloads\\JanVision_2.ipynb\\runs\\detect\\train7\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# 1. Define the Dataset Config locally\n",
    "import yaml\n",
    "import torch\n",
    "import os\n",
    "\n",
    "# Set the correct dataset root path (absolute path as provided)\n",
    "dataset_root = r'C:/Users/praha/Downloads/JanVision_2.ipynb/janvision_dataset/janvision_dataset'\n",
    "data_config = {\n",
    "    'path': dataset_root, # Absolute path to dataset root\n",
    "    'train': os.path.join(dataset_root, 'images', 'train'),\n",
    "    'val': os.path.join(dataset_root, 'images', 'val'),\n",
    "    'names': {\n",
    "        0: 'Keratoconus',\n",
    "        1: 'Normal',\n",
    "        2: 'Suspect'\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save the config file\n",
    "with open('data.yaml', 'w') as f:\n",
    "    yaml.dump(data_config, f)\n",
    "\n",
    "# 2. Train using NVIDIA RTX 3050 (CUDA)\n",
    "if __name__ == '__main__':\n",
    "    # Detection for your NVIDIA GPU\n",
    "    device = '0' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "    if device == '0':\n",
    "        print(f\"✅ Success! RTX 3050 detected. Training on GPU.\")\n",
    "    else:\n",
    "        print(f\"⚠️ GPU not detected. Training on Ryzen CPU. (Check CUDA installation)\")\n",
    "\n",
    "    model = YOLO(\"yolo11n.pt\")  # Load Nano model (Fastest)\n",
    "\n",
    "    # Train\n",
    "    model.train(\n",
    "        data=\"data.yaml\", \n",
    "        epochs=15, \n",
    "        imgsz=640, \n",
    "        batch=16, \n",
    "        device=device\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb6c3c6",
   "metadata": {},
   "source": [
    "## Model Evaluation and Visualization\n",
    "This section computes the accuracy, F1 score, confusion matrix, ROC curve, and loss curve for your YOLO model. It also compares the accuracy of two classes and checks for overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e2b738",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using weights file: C:/Users/praha/Downloads/JanVision_2.ipynb/runs/detect\\train7\\weights\\best.pt\n",
      "\n",
      "image 1/1 C:\\Users\\praha\\Downloads\\JanVision_2.ipynb\\janvision_dataset\\janvision_dataset\\images\\val\\eye_103_0.jpg: 640x640 1 Suspect, 92.4ms\n",
      "Speed: 4.3ms preprocess, 92.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\praha\\Downloads\\JanVision_2.ipynb\\janvision_dataset\\janvision_dataset\\images\\val\\eye_107_0.jpg: 640x640 1 Keratoconus, 80.9ms\n",
      "Speed: 3.9ms preprocess, 80.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\praha\\Downloads\\JanVision_2.ipynb\\janvision_dataset\\janvision_dataset\\images\\val\\eye_108_0.jpg: 640x640 1 Keratoconus, 81.0ms\n",
      "Speed: 2.7ms preprocess, 81.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\praha\\Downloads\\JanVision_2.ipynb\\janvision_dataset\\janvision_dataset\\images\\val\\eye_114_0.jpg: 640x640 1 Keratoconus, 90.3ms\n",
      "Speed: 4.1ms preprocess, 90.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\praha\\Downloads\\JanVision_2.ipynb\\janvision_dataset\\janvision_dataset\\images\\val\\eye_125_0.jpg: 640x640 1 Keratoconus, 87.4ms\n",
      "Speed: 3.9ms preprocess, 87.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\praha\\Downloads\\JanVision_2.ipynb\\janvision_dataset\\janvision_dataset\\images\\val\\eye_12_0.jpg: 640x640 1 Keratoconus, 81.3ms\n",
      "Speed: 3.4ms preprocess, 81.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\praha\\Downloads\\JanVision_2.ipynb\\janvision_dataset\\janvision_dataset\\images\\val\\eye_130_0.jpg: 640x640 1 Keratoconus, 78.6ms\n",
      "Speed: 2.6ms preprocess, 78.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\praha\\Downloads\\JanVision_2.ipynb\\janvision_dataset\\janvision_dataset\\images\\val\\eye_133_0.jpg: 640x640 1 Keratoconus, 82.0ms\n",
      "Speed: 3.3ms preprocess, 82.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\praha\\Downloads\\JanVision_2.ipynb\\janvision_dataset\\janvision_dataset\\images\\val\\eye_135_0.jpg: 640x640 1 Keratoconus, 82.3ms\n",
      "Speed: 3.0ms preprocess, 82.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\praha\\Downloads\\JanVision_2.ipynb\\janvision_dataset\\janvision_dataset\\images\\val\\eye_140_0.jpg: 640x640 1 Keratoconus, 83.1ms\n",
      "Speed: 3.9ms preprocess, 83.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\praha\\Downloads\\JanVision_2.ipynb\\janvision_dataset\\janvision_dataset\\images\\val\\eye_144_0.jpg: 640x640 1 Keratoconus, 77.7ms\n",
      "Speed: 2.8ms preprocess, 77.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\praha\\Downloads\\JanVision_2.ipynb\\janvision_dataset\\janvision_dataset\\images\\val\\eye_147_0.jpg: 640x640 1 Keratoconus, 77.3ms\n",
      "Speed: 3.5ms preprocess, 77.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\praha\\Downloads\\JanVision_2.ipynb\\janvision_dataset\\janvision_dataset\\images\\val\\eye_150_1.jpg: 640x640 1 Normal, 78.1ms\n",
      "Speed: 2.8ms preprocess, 78.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\praha\\Downloads\\JanVision_2.ipynb\\janvision_dataset\\janvision_dataset\\images\\val\\eye_152_1.jpg: 640x640 1 Normal, 86.2ms\n",
      "Speed: 3.4ms preprocess, 86.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\praha\\Downloads\\JanVision_2.ipynb\\janvision_dataset\\janvision_dataset\\images\\val\\eye_153_1.jpg: 640x640 1 Normal, 89.9ms\n",
      "Speed: 3.6ms preprocess, 89.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\praha\\Downloads\\JanVision_2.ipynb\\janvision_dataset\\janvision_dataset\\images\\val\\eye_156_1.jpg: 640x640 1 Normal, 85.9ms\n",
      "Speed: 3.2ms preprocess, 85.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\praha\\Downloads\\JanVision_2.ipynb\\janvision_dataset\\janvision_dataset\\images\\val\\eye_167_1.jpg: 640x640 1 Normal, 86.1ms\n",
      "Speed: 3.3ms preprocess, 86.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\praha\\Downloads\\JanVision_2.ipynb\\janvision_dataset\\janvision_dataset\\images\\val\\eye_169_1.jpg: 640x640 1 Normal, 89.8ms\n",
      "Speed: 4.1ms preprocess, 89.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\praha\\Downloads\\JanVision_2.ipynb\\janvision_dataset\\janvision_dataset\\images\\val\\eye_16_0.jpg: 640x640 1 Suspect, 84.1ms\n",
      "Speed: 3.1ms preprocess, 84.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\praha\\Downloads\\JanVision_2.ipynb\\janvision_dataset\\janvision_dataset\\images\\val\\eye_172_1.jpg: 640x640 1 Normal, 86.1ms\n",
      "Speed: 3.6ms preprocess, 86.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\praha\\Downloads\\JanVision_2.ipynb\\janvision_dataset\\janvision_dataset\\images\\val\\eye_174_1.jpg: 640x640 1 Normal, 90.0ms\n",
      "Speed: 3.8ms preprocess, 90.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\praha\\Downloads\\JanVision_2.ipynb\\janvision_dataset\\janvision_dataset\\images\\val\\eye_177_1.jpg: 640x640 1 Normal, 91.3ms\n",
      "Speed: 4.1ms preprocess, 91.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\praha\\Downloads\\JanVision_2.ipynb\\janvision_dataset\\janvision_dataset\\images\\val\\eye_186_1.jpg: 640x640 1 Normal, 89.8ms\n",
      "Speed: 3.1ms preprocess, 89.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\praha\\Downloads\\JanVision_2.ipynb\\janvision_dataset\\janvision_dataset\\images\\val\\eye_192_1.jpg: 640x640 1 Normal, 88.9ms\n",
      "Speed: 3.0ms preprocess, 88.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\praha\\Downloads\\JanVision_2.ipynb\\janvision_dataset\\janvision_dataset\\images\\val\\eye_197_1.jpg: 640x640 1 Normal, 85.2ms\n",
      "Speed: 3.6ms preprocess, 85.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\praha\\Downloads\\JanVision_2.ipynb\\janvision_dataset\\janvision_dataset\\images\\val\\eye_200_1.jpg: 640x640 1 Normal, 88.9ms\n",
      "Speed: 3.0ms preprocess, 88.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\praha\\Downloads\\JanVision_2.ipynb\\janvision_dataset\\janvision_dataset\\images\\val\\eye_205_1.jpg: 640x640 1 Normal, 82.2ms\n",
      "Speed: 3.3ms preprocess, 82.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\praha\\Downloads\\JanVision_2.ipynb\\janvision_dataset\\janvision_dataset\\images\\val\\eye_208_1.jpg: 640x640 1 Normal, 86.4ms\n",
      "Speed: 3.5ms preprocess, 86.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\praha\\Downloads\\JanVision_2.ipynb\\janvision_dataset\\janvision_dataset\\images\\val\\eye_209_1.jpg: 640x640 1 Normal, 80.5ms\n",
      "Speed: 4.3ms preprocess, 80.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\praha\\Downloads\\JanVision_2.ipynb\\janvision_dataset\\janvision_dataset\\images\\val\\eye_20_0.jpg: 640x640 1 Keratoconus, 79.6ms\n",
      "Speed: 3.8ms preprocess, 79.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\praha\\Downloads\\JanVision_2.ipynb\\janvision_dataset\\janvision_dataset\\images\\val\\eye_220_1.jpg: 640x640 1 Normal, 79.6ms\n",
      "Speed: 3.2ms preprocess, 79.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\praha\\Downloads\\JanVision_2.ipynb\\janvision_dataset\\janvision_dataset\\images\\val\\eye_222_1.jpg: 640x640 1 Normal, 80.1ms\n",
      "Speed: 3.4ms preprocess, 80.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\praha\\Downloads\\JanVision_2.ipynb\\janvision_dataset\\janvision_dataset\\images\\val\\eye_225_1.jpg: 640x640 1 Normal, 79.2ms\n",
      "Speed: 2.7ms preprocess, 79.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\praha\\Downloads\\JanVision_2.ipynb\\janvision_dataset\\janvision_dataset\\images\\val\\eye_227_1.jpg: 640x640 1 Normal, 81.7ms\n",
      "Speed: 3.5ms preprocess, 81.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\praha\\Downloads\\JanVision_2.ipynb\\janvision_dataset\\janvision_dataset\\images\\val\\eye_228_1.jpg: 640x640 1 Normal, 89.0ms\n",
      "Speed: 2.8ms preprocess, 89.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\praha\\Downloads\\JanVision_2.ipynb\\janvision_dataset\\janvision_dataset\\images\\val\\eye_232_1.jpg: 640x640 1 Normal, 79.6ms\n",
      "Speed: 3.0ms preprocess, 79.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\praha\\Downloads\\JanVision_2.ipynb\\janvision_dataset\\janvision_dataset\\images\\val\\eye_234_1.jpg: 640x640 1 Normal, 78.3ms\n",
      "Speed: 3.5ms preprocess, 78.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\praha\\Downloads\\JanVision_2.ipynb\\janvision_dataset\\janvision_dataset\\images\\val\\eye_235_1.jpg: 640x640 1 Normal, 78.8ms\n",
      "Speed: 2.6ms preprocess, 78.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\praha\\Downloads\\JanVision_2.ipynb\\janvision_dataset\\janvision_dataset\\images\\val\\eye_238_1.jpg: 640x640 1 Normal, 80.6ms\n",
      "Speed: 3.2ms preprocess, 80.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\praha\\Downloads\\JanVision_2.ipynb\\janvision_dataset\\janvision_dataset\\images\\val\\eye_23_0.jpg: 640x640 1 Keratoconus, 80.2ms\n",
      "Speed: 3.4ms preprocess, 80.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\praha\\Downloads\\JanVision_2.ipynb\\janvision_dataset\\janvision_dataset\\images\\val\\eye_240_1.jpg: 640x640 1 Normal, 81.5ms\n",
      "Speed: 3.6ms preprocess, 81.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\praha\\Downloads\\JanVision_2.ipynb\\janvision_dataset\\janvision_dataset\\images\\val\\eye_241_1.jpg: 640x640 1 Normal, 80.8ms\n",
      "Speed: 3.8ms preprocess, 80.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\praha\\Downloads\\JanVision_2.ipynb\\janvision_dataset\\janvision_dataset\\images\\val\\eye_243_1.jpg: 640x640 1 Normal, 81.7ms\n",
      "Speed: 3.7ms preprocess, 81.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\praha\\Downloads\\JanVision_2.ipynb\\janvision_dataset\\janvision_dataset\\images\\val\\eye_246_1.jpg: 640x640 1 Normal, 81.2ms\n",
      "Speed: 2.8ms preprocess, 81.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\praha\\Downloads\\JanVision_2.ipynb\\janvision_dataset\\janvision_dataset\\images\\val\\eye_249_1.jpg: 640x640 1 Normal, 79.7ms\n",
      "Speed: 3.2ms preprocess, 79.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\praha\\Downloads\\JanVision_2.ipynb\\janvision_dataset\\janvision_dataset\\images\\val\\eye_24_0.jpg: 640x640 1 Keratoconus, 79.7ms\n",
      "Speed: 3.6ms preprocess, 79.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\praha\\Downloads\\JanVision_2.ipynb\\janvision_dataset\\janvision_dataset\\images\\val\\eye_254_1.jpg: 640x640 1 Normal, 104.8ms\n",
      "Speed: 3.5ms preprocess, 104.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\praha\\Downloads\\JanVision_2.ipynb\\janvision_dataset\\janvision_dataset\\images\\val\\eye_267_1.jpg: 640x640 1 Normal, 78.8ms\n",
      "Speed: 4.1ms preprocess, 78.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\praha\\Downloads\\JanVision_2.ipynb\\janvision_dataset\\janvision_dataset\\images\\val\\eye_26_0.jpg: 640x640 1 Keratoconus, 78.0ms\n",
      "Speed: 3.4ms preprocess, 78.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\praha\\Downloads\\JanVision_2.ipynb\\janvision_dataset\\janvision_dataset\\images\\val\\eye_283_1.jpg: 640x640 1 Normal, 78.1ms\n",
      "Speed: 2.8ms preprocess, 78.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\praha\\Downloads\\JanVision_2.ipynb\\janvision_dataset\\janvision_dataset\\images\\val\\eye_285_1.jpg: 640x640 1 Normal, 82.2ms\n",
      "Speed: 2.7ms preprocess, 82.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\praha\\Downloads\\JanVision_2.ipynb\\janvision_dataset\\janvision_dataset\\images\\val\\eye_286_1.jpg: 640x640 1 Normal, 78.3ms\n",
      "Speed: 3.3ms preprocess, 78.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\praha\\Downloads\\JanVision_2.ipynb\\janvision_dataset\\janvision_dataset\\images\\val\\eye_298_1.jpg: 640x640 1 Normal, 76.2ms\n",
      "Speed: 3.1ms preprocess, 76.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\praha\\Downloads\\JanVision_2.ipynb\\janvision_dataset\\janvision_dataset\\images\\val\\eye_2_0.jpg: 640x640 1 Keratoconus, 80.8ms\n",
      "Speed: 3.0ms preprocess, 80.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\praha\\Downloads\\JanVision_2.ipynb\\janvision_dataset\\janvision_dataset\\images\\val\\eye_305_2.jpg: 640x640 1 Suspect, 79.3ms\n",
      "Speed: 3.0ms preprocess, 79.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\praha\\Downloads\\JanVision_2.ipynb\\janvision_dataset\\janvision_dataset\\images\\val\\eye_309_2.jpg: 640x640 1 Suspect, 79.3ms\n",
      "Speed: 3.7ms preprocess, 79.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\praha\\Downloads\\JanVision_2.ipynb\\janvision_dataset\\janvision_dataset\\images\\val\\eye_322_2.jpg: 640x640 1 Suspect, 80.1ms\n",
      "Speed: 2.9ms preprocess, 80.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\praha\\Downloads\\JanVision_2.ipynb\\janvision_dataset\\janvision_dataset\\images\\val\\eye_326_2.jpg: 640x640 1 Suspect, 80.0ms\n",
      "Speed: 3.8ms preprocess, 80.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\praha\\Downloads\\JanVision_2.ipynb\\janvision_dataset\\janvision_dataset\\images\\val\\eye_327_2.jpg: 640x640 1 Suspect, 77.8ms\n",
      "Speed: 3.1ms preprocess, 77.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\praha\\Downloads\\JanVision_2.ipynb\\janvision_dataset\\janvision_dataset\\images\\val\\eye_330_2.jpg: 640x640 1 Suspect, 80.9ms\n",
      "Speed: 3.4ms preprocess, 80.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\praha\\Downloads\\JanVision_2.ipynb\\janvision_dataset\\janvision_dataset\\images\\val\\eye_332_2.jpg: 640x640 1 Suspect, 78.2ms\n",
      "Speed: 2.8ms preprocess, 78.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\praha\\Downloads\\JanVision_2.ipynb\\janvision_dataset\\janvision_dataset\\images\\val\\eye_338_2.jpg: 640x640 1 Suspect, 78.0ms\n",
      "Speed: 2.9ms preprocess, 78.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\praha\\Downloads\\JanVision_2.ipynb\\janvision_dataset\\janvision_dataset\\images\\val\\eye_348_2.jpg: 640x640 1 Suspect, 79.9ms\n",
      "Speed: 3.6ms preprocess, 79.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\praha\\Downloads\\JanVision_2.ipynb\\janvision_dataset\\janvision_dataset\\images\\val\\eye_350_2.jpg: 640x640 1 Suspect, 80.8ms\n",
      "Speed: 3.6ms preprocess, 80.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\praha\\Downloads\\JanVision_2.ipynb\\janvision_dataset\\janvision_dataset\\images\\val\\eye_355_2.jpg: 640x640 1 Normal, 81.9ms\n",
      "Speed: 3.8ms preprocess, 81.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\praha\\Downloads\\JanVision_2.ipynb\\janvision_dataset\\janvision_dataset\\images\\val\\eye_357_2.jpg: 640x640 1 Suspect, 80.8ms\n",
      "Speed: 3.4ms preprocess, 80.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\praha\\Downloads\\JanVision_2.ipynb\\janvision_dataset\\janvision_dataset\\images\\val\\eye_360_2.jpg: 640x640 1 Suspect, 75.8ms\n",
      "Speed: 3.5ms preprocess, 75.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\praha\\Downloads\\JanVision_2.ipynb\\janvision_dataset\\janvision_dataset\\images\\val\\eye_364_2.jpg: 640x640 1 Suspect, 79.4ms\n",
      "Speed: 3.6ms preprocess, 79.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\praha\\Downloads\\JanVision_2.ipynb\\janvision_dataset\\janvision_dataset\\images\\val\\eye_366_2.jpg: 640x640 1 Suspect, 80.0ms\n",
      "Speed: 2.7ms preprocess, 80.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\praha\\Downloads\\JanVision_2.ipynb\\janvision_dataset\\janvision_dataset\\images\\val\\eye_367_2.jpg: 640x640 1 Suspect, 83.0ms\n",
      "Speed: 3.2ms preprocess, 83.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\praha\\Downloads\\JanVision_2.ipynb\\janvision_dataset\\janvision_dataset\\images\\val\\eye_373_2.jpg: 640x640 1 Suspect, 78.7ms\n",
      "Speed: 3.1ms preprocess, 78.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\praha\\Downloads\\JanVision_2.ipynb\\janvision_dataset\\janvision_dataset\\images\\val\\eye_382_2.jpg: 640x640 1 Suspect, 75.7ms\n",
      "Speed: 3.4ms preprocess, 75.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\praha\\Downloads\\JanVision_2.ipynb\\janvision_dataset\\janvision_dataset\\images\\val\\eye_386_2.jpg: 640x640 1 Suspect, 77.9ms\n",
      "Speed: 3.8ms preprocess, 77.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\praha\\Downloads\\JanVision_2.ipynb\\janvision_dataset\\janvision_dataset\\images\\val\\eye_394_2.jpg: 640x640 1 Suspect, 86.1ms\n",
      "Speed: 2.7ms preprocess, 86.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\praha\\Downloads\\JanVision_2.ipynb\\janvision_dataset\\janvision_dataset\\images\\val\\eye_39_0.jpg: 640x640 1 Keratoconus, 79.0ms\n",
      "Speed: 2.6ms preprocess, 79.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\praha\\Downloads\\JanVision_2.ipynb\\janvision_dataset\\janvision_dataset\\images\\val\\eye_40_0.jpg: 640x640 1 Keratoconus, 76.6ms\n",
      "Speed: 2.7ms preprocess, 76.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\praha\\Downloads\\JanVision_2.ipynb\\janvision_dataset\\janvision_dataset\\images\\val\\eye_415_2.jpg: 640x640 1 Suspect, 80.2ms\n",
      "Speed: 2.8ms preprocess, 80.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\praha\\Downloads\\JanVision_2.ipynb\\janvision_dataset\\janvision_dataset\\images\\val\\eye_63_0.jpg: 640x640 1 Keratoconus, 75.6ms\n",
      "Speed: 3.2ms preprocess, 75.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\praha\\Downloads\\JanVision_2.ipynb\\janvision_dataset\\janvision_dataset\\images\\val\\eye_6_0.jpg: 640x640 1 Keratoconus, 78.3ms\n",
      "Speed: 3.5ms preprocess, 78.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\praha\\Downloads\\JanVision_2.ipynb\\janvision_dataset\\janvision_dataset\\images\\val\\eye_72_0.jpg: 640x640 1 Keratoconus, 79.4ms\n",
      "Speed: 2.7ms preprocess, 79.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\praha\\Downloads\\JanVision_2.ipynb\\janvision_dataset\\janvision_dataset\\images\\val\\eye_73_0.jpg: 640x640 1 Keratoconus, 80.4ms\n",
      "Speed: 3.6ms preprocess, 80.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\praha\\Downloads\\JanVision_2.ipynb\\janvision_dataset\\janvision_dataset\\images\\val\\eye_83_0.jpg: 640x640 1 Keratoconus, 78.0ms\n",
      "Speed: 3.6ms preprocess, 78.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\praha\\Downloads\\JanVision_2.ipynb\\janvision_dataset\\janvision_dataset\\images\\val\\eye_88_0.jpg: 640x640 1 Keratoconus, 1 Suspect, 77.0ms\n",
      "Speed: 2.9ms preprocess, 77.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\praha\\Downloads\\JanVision_2.ipynb\\janvision_dataset\\janvision_dataset\\images\\val\\eye_8_0.jpg: 640x640 1 Keratoconus, 78.3ms\n",
      "Speed: 3.5ms preprocess, 78.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\praha\\Downloads\\JanVision_2.ipynb\\janvision_dataset\\janvision_dataset\\images\\val\\eye_96_0.jpg: 640x640 1 Keratoconus, 78.9ms\n",
      "Speed: 2.8ms preprocess, 78.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Validation Accuracy: 0.9529\n",
      "F1 Score: 0.9531\n",
      "Precision (P): 0.9563\n",
      "Recall (R): 0.9529\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 600x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 Accuracy: 0.8929, Class 1 Accuracy: 1.0000\n",
      "Warning: Large accuracy difference between classes.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, roc_curve, auc, roc_auc_score, precision_score, recall_score\n",
    "from ultralytics import YOLO\n",
    "import torch\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# Try to automatically find the best.pt or last.pt file in all subdirectories of runs/detect\n",
    "weights_path = None\n",
    "for root, dirs, files in os.walk(r'C:/Users/praha/Downloads/JanVision_2.ipynb/runs/detect'):\n",
    "    for fname in files:\n",
    "        if fname in ['best.pt', 'last.pt']:\n",
    "            weights_path = os.path.join(root, fname)\n",
    "            break\n",
    "    if weights_path:\n",
    "        break\n",
    "\n",
    "if weights_path and os.path.exists(weights_path):\n",
    "    print(f'Using weights file: {weights_path}')\n",
    "    # Load trained model\n",
    "    model = YOLO(weights_path)\n",
    "\n",
    "    # Load validation images and labels\n",
    "    val_images_dir = r'C:/Users/praha/Downloads/JanVision_2.ipynb/janvision_dataset/janvision_dataset/images/val'\n",
    "    val_labels_dir = r'C:/Users/praha/Downloads/JanVision_2.ipynb/janvision_dataset/janvision_dataset/labels/val'\n",
    "\n",
    "    # Helper: get image and label paths\n",
    "    val_image_paths = sorted(glob.glob(os.path.join(val_images_dir, '*.jpg')))\n",
    "    val_label_paths = sorted(glob.glob(os.path.join(val_labels_dir, '*.txt')))\n",
    "\n",
    "    # Ensure the number of images and labels match\n",
    "    if len(val_image_paths) != len(val_label_paths):\n",
    "        raise ValueError(f\"Number of validation images ({len(val_image_paths)}) and labels ({len(val_label_paths)}) do not match. Please check your dataset.\")\n",
    "\n",
    "    # Helper: parse YOLO label file (single class per file assumed)\n",
    "    def parse_label(label_path):\n",
    "        with open(label_path, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "        # Each line: class x_center y_center width height\n",
    "        return [int(line.split()[0]) for line in lines]\n",
    "\n",
    "    # Gather ground truth and predictions\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    y_scores = []\n",
    "\n",
    "    for img_path, label_path in zip(val_image_paths, val_label_paths):\n",
    "        gt_classes = parse_label(label_path)\n",
    "        y_true.extend(gt_classes)\n",
    "        \n",
    "        results = model(img_path)\n",
    "        pred_classes = [int(box.cls.cpu().numpy()[0]) for box in results[0].boxes] if len(results[0].boxes) > 0 else [-1]\n",
    "        y_pred.extend(pred_classes)\n",
    "        # For ROC: get max confidence for each class\n",
    "        if len(results[0].boxes) > 0:\n",
    "            y_scores.extend(results[0].boxes.conf.cpu().numpy())\n",
    "        else:\n",
    "            y_scores.append(0)\n",
    "\n",
    "    # Make y_true and y_pred the same length (truncate to shortest)\n",
    "    min_len = min(len(y_true), len(y_pred))\n",
    "    y_true = np.array(y_true[:min_len])\n",
    "    y_pred = np.array(y_pred[:min_len])\n",
    "    mask = y_pred != -1\n",
    "    y_true = y_true[mask]\n",
    "    y_pred = y_pred[mask]\n",
    "\n",
    "    # Accuracy, F1, Precision, Recall\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "    precision = precision_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "    recall = recall_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "    print(f'Validation Accuracy: {acc:.4f}')\n",
    "    print(f'F1 Score: {f1:.4f}')\n",
    "    print(f'Precision (P): {precision:.4f}')\n",
    "    print(f'Recall (R): {recall:.4f}')\n",
    "\n",
    "    # Confusion Matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(6,5))\n",
    "    plt.imshow(cm, cmap='Blues')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "\n",
    "    # ROC Curve (for each class)\n",
    "    plt.figure(figsize=(8,6))\n",
    "    for c in np.unique(y_true):\n",
    "        y_true_bin = (y_true == c).astype(int)\n",
    "        y_pred_bin = (y_pred == c).astype(int)\n",
    "        fpr, tpr, _ = roc_curve(y_true_bin, y_pred_bin)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        plt.plot(fpr, tpr, label=f'Class {c} (AUC = {roc_auc:.2f})')\n",
    "    plt.plot([0,1],[0,1],'k--')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curve (Validation)')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # mAP50 (mean Average Precision at IoU=0.5)\n",
    "    import yaml\n",
    "    results_path = os.path.join(os.path.dirname(os.path.dirname(weights_path)), 'results.yaml')\n",
    "    map50 = None\n",
    "    if os.path.exists(results_path):\n",
    "        with open(results_path) as f:\n",
    "            results = yaml.safe_load(f)\n",
    "        # Print all keys for debugging\n",
    "        print('results.yaml keys:', list(results.keys()))\n",
    "        # Print metrics keys if present\n",
    "        if 'metrics' in results:\n",
    "            print('metrics keys:', list(results['metrics'].keys()))\n",
    "        # Try all possible key names for mAP50\n",
    "        possible_keys = [\n",
    "            'metrics/mAP_0.5', 'metrics/mAP50', 'metrics/map_50', 'metrics/precision_50',\n",
    "            'map_50', 'mAP_0.5', 'mAP50', 'precision_50', 'metrics/box/mAP_0.5', 'metrics/box/mAP50'\n",
    "        ]\n",
    "        metrics = results.get('metrics', {})\n",
    "        for k in possible_keys:\n",
    "            # Try in metrics dict\n",
    "            if k in metrics:\n",
    "                map50 = metrics[k]\n",
    "                break\n",
    "            # Try in root dict\n",
    "            if k in results:\n",
    "                map50 = results[k]\n",
    "                break\n",
    "        if map50 is not None:\n",
    "            print(f'mAP50 (mean Average Precision @ IoU=0.5): {map50:.4f}')\n",
    "        else:\n",
    "            print('mAP50 value not found in results.yaml. Please check the printed keys above to locate the correct key.')\n",
    "        # Loss Curve\n",
    "        train_loss = None\n",
    "        val_loss = None\n",
    "        if 'metrics' in results:\n",
    "            metrics = results['metrics']\n",
    "            if 'train/box_loss' in metrics:\n",
    "                train_loss = metrics['train/box_loss']\n",
    "            if 'metrics/val/box_loss' in metrics:\n",
    "                val_loss = metrics['metrics/val/box_loss']\n",
    "            elif 'val/box_loss' in metrics:\n",
    "                val_loss = metrics['val/box_loss']\n",
    "        # Plot loss curves if available\n",
    "        if train_loss is not None:\n",
    "            plt.plot(train_loss, label='Box Loss (Train)')\n",
    "        if val_loss is not None:\n",
    "            plt.plot(val_loss, label='Box Loss (Val)')\n",
    "        if train_loss is not None or val_loss is not None:\n",
    "            plt.xlabel('Epoch')\n",
    "            plt.ylabel('Loss')\n",
    "            plt.title('Training/Validation Loss Curve')\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "        # Overfitting check\n",
    "        if train_loss is not None and val_loss is not None:\n",
    "            if val_loss[-1] > train_loss[-1]:\n",
    "                print('Possible overfitting detected: Validation loss is higher than training loss.')\n",
    "\n",
    "    # Plot accuracy for 2 classes\n",
    "    if len(np.unique(y_true)) >= 2:\n",
    "        accs = []\n",
    "        for c in [0,1]:\n",
    "            mask = y_true == c\n",
    "            accs.append(accuracy_score(y_true[mask], y_pred[mask]))\n",
    "        plt.bar(['Class 0', 'Class 1'], accs)\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.title('Accuracy for Class 0 vs Class 1')\n",
    "        plt.show()\n",
    "        print(f'Class 0 Accuracy: {accs[0]:.4f}, Class 1 Accuracy: {accs[1]:.4f}')\n",
    "        if abs(accs[0] - accs[1]) > 0.1:\n",
    "            print('Warning: Large accuracy difference between classes.')\n",
    "else:\n",
    "    print('Evaluation skipped: No YOLO weights file (best.pt or last.pt) found in any runs/detect subdirectory. Please check your training output.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
